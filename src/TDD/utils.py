# utils.py
import os
import json
import psycopg2
import pandas as pd  # ğŸ§© [ì¶”ê°€] ì°¨íŠ¸ ë°ì´í„°ë¥¼ ë‹¤ë£¨ê¸° ìœ„í•œ pandas ì„í¬íŠ¸
import streamlit as st

# ğŸ§© [ì¶”ê°€] ê³µí†µìœ¼ë¡œ ì‚¬ìš©ë  ê²½ë¡œ ë° ì„¤ì • íŒŒì¼ ì •ì˜
CONFIG_FILE = "dashboard_config.json"
DATA_PATH = os.path.expanduser("~/data_collection/habilis_dataset_manager/data/raw")

# ğŸ§© [ì´ë™] DB ì—°ê²° í•¨ìˆ˜ ë¶„ë¦¬
@st.cache_resource
def init_connection():
    return psycopg2.connect(
        host="localhost",
        database="tommoro_db",
        user="tommoro",
        password="tommoro4011"
    )

# ğŸ§© [ì´ë™] ì¿¼ë¦¬ ì‹¤í–‰ í•¨ìˆ˜ ë¶„ë¦¬
def run_query(query):
    with init_connection().cursor() as cur:
        cur.execute(query)
        return cur.fetchall()

# ğŸ§© [ì´ë™] ì„¤ì • ë¡œë“œ í•¨ìˆ˜ ë¶„ë¦¬
def load_config():
    if os.path.exists(CONFIG_FILE):
        try:
            with open(CONFIG_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except: pass
    return {"target_hours": 4.0, "left_operators": [], "right_operators": [], "task_targets": {}}

# ğŸ§© [ì´ë™] ì„¤ì • ì €ì¥ í•¨ìˆ˜ ë¶„ë¦¬
def save_config():
    new_conf = {
        "target_hours": st.session_state.test_target_input,
        "left_operators": st.session_state.test_left_input,
        "right_operators": st.session_state.test_right_input,
        "task_targets": st.session_state.get("task_targets", {})
    }
    with open(CONFIG_FILE, "w", encoding="utf-8") as f:
        json.dump(new_conf, f, ensure_ascii=False)

# ğŸ§© [ì´ë™] í´ë” ë°ì´í„° ì¶”ì¶œ í•¨ìˆ˜ ë¶„ë¦¬
def get_folder_data(folder_path):
    duration, task_name = 0, "Unknown"
    yaml_path = os.path.join(folder_path, "metadata.yaml")
    json_path = os.path.join(folder_path, "metacard.json")
    if os.path.exists(yaml_path) and os.path.exists(json_path):
        try:
            with open(yaml_path, "r") as f:
                for line in f:
                    if "nanoseconds:" in line:
                        duration = int(line.split(":")[-1].strip()) / 1e9
                        break
            with open(json_path, "r", encoding="utf-8") as f:
                task_name = json.load(f).get("task_name", "Unknown")
        except: pass
    return task_name, duration

# ğŸ§© [ì´ë™] ì‹œê°„ í¬ë§·íŒ… í•¨ìˆ˜ ë¶„ë¦¬
def safe_extract_time(folder_name: str) -> str:
    try:
        parts = folder_name.split("_")
        if len(parts) >= 2 and len(parts[1]) >= 4:
            return f"{parts[1][:2]}:{parts[1][2:4]}"
    except: pass
    return "--:--"

# ğŸ§© [ì´ë™] ì‹œê°„ í¬ë§·íŒ… í•¨ìˆ˜ ë¶„ë¦¬
def format_h_m(seconds):
    h = int(seconds // 3600)
    m = int((seconds % 3600) // 60)
    if h > 0:
        return f"{h}ì‹œê°„ {m}ë¶„"
    return f"{m}ë¶„"

# ğŸ§© [ì¶”ê°€] ëˆ„ë½ë˜ì—ˆë˜ ì»¨ë² ì´ì–´ ì»¨íŠ¸ë¡¤ëŸ¬ ìƒì„± í•¨ìˆ˜
def get_conveyor_controller():
    try:
        # í¬íŠ¸ ì„¤ì • (í•„ìš”ì— ë”°ë¼ ìˆ˜ì • ê°€ëŠ¥)
        port_config = {'a': None} 
        # ConveyorControllerê°€ ì •ì˜/ì„í¬íŠ¸ë˜ì–´ ìˆì–´ì•¼ ë™ì‘í•©ë‹ˆë‹¤.
        controller = ConveyorController(port_config)
        return controller
    except Exception as e:
        # ì—°ê²° ì‹¤íŒ¨ ì‹œ None ë°˜í™˜ (ëŒ€ì‹œë³´ë“œê°€ ë©ˆì¶”ì§€ ì•Šë„ë¡)
        return None

# -------------------------------------------------------------------
# ğŸ“Š ëŒ€ì‹œë³´ë“œ ì¤‘ì•™ ì°¨íŠ¸ìš© ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ (utils.py í•˜ë‹¨)
# -------------------------------------------------------------------
@st.cache_data(ttl=60)
def get_dashboard_charts_data():
    """ê°„íŠ¸ ì°¨íŠ¸ ë° íŒŒì´ ì°¨íŠ¸ìš© ë°ì´í„° ë¡œë“œ"""
    
    # ğŸ§© [ìˆ˜ì • 3] "ì „ì²´ ê¸°ê°„"ì— ëª¨ë“  í”„ë¡œì íŠ¸ê°€ ëœ¨ë„ë¡ WHERE í•„í„° ì¡°ê±´ í•´ì œ
    gantt_query = """
        SELECT 
            project_name AS "Task",
            start_date AS "Start",
            end_date AS "Finish"
        FROM projects
        WHERE start_date IS NOT NULL AND end_date IS NOT NULL;
    """
    
    # 2. í”„ë¡œì íŠ¸ë³„ ì§„í–‰ë¥  ë°ì´í„° ì¿¼ë¦¬
    progress_query = """
        SELECT 
            p.project_name, 
            p.status,
            SUM(CAST(sl.duration AS NUMERIC)) / 3600.0 AS collected_hours
        FROM projects p
        JOIN tasks t ON p.project_id = t.project_id
        JOIN subtasks s ON t.task_id = s.task_id
        JOIN subtask_logs sl ON s.subtask_id = sl.subtask_id
        GROUP BY p.project_name, p.status
        HAVING SUM(CAST(sl.duration AS NUMERIC)) > 0;
    """
    
    # 3. Primitive Data ë¹„ìœ¨ ì¿¼ë¦¬
    primitive_query = """
        SELECT 
            CASE 
                WHEN p.project_name ILIKE '%Picking%' OR p.project_name ILIKE '%Play%' OR p.project_name ILIKE '%BI%' THEN 'Primitive Data'
                ELSE 'Task Data'
            END AS data_type,
            SUM(CAST(sl.duration AS NUMERIC)) / 3600.0 AS collected_hours
        FROM projects p
        JOIN tasks t ON p.project_id = t.project_id
        JOIN subtasks s ON t.task_id = s.task_id
        JOIN subtask_logs sl ON s.subtask_id = sl.subtask_id
        GROUP BY 1;
    """
    
    gantt_rows = run_query(gantt_query)
    progress_rows = run_query(progress_query)
    primitive_rows = run_query(primitive_query)
    
    df_gantt = pd.DataFrame(gantt_rows, columns=["Task", "Start", "Finish"])
    df_progress = pd.DataFrame(progress_rows, columns=["project_name", "status", "collected_hours"])
    df_primitive = pd.DataFrame(primitive_rows, columns=["data_type", "collected_hours"])
    
    # íŒŒì´ì¬ ì½”ë“œë‹¨ì—ì„œ ì•ˆì „í•˜ê²Œ íƒ€ì… ë³€í™˜
    df_gantt['Start'] = pd.to_datetime(df_gantt['Start'], errors='coerce')
    df_gantt['Finish'] = pd.to_datetime(df_gantt['Finish'], errors='coerce')
    
    df_progress['collected_hours'] = pd.to_numeric(df_progress['collected_hours'], errors='coerce').fillna(0.0)
    df_primitive['collected_hours'] = pd.to_numeric(df_primitive['collected_hours'], errors='coerce').fillna(0.0)
    
    return df_gantt, df_progress, df_primitive